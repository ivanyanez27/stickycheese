# ğŸ§€ StickyCheese

**A privacy-first LLM chat interface.** Bring your own API key, chat with multiple models, and keep everything on your device.

No accounts. No backend. No data collection. Just you and the model.

---

## What is this?

StickyCheese is a self-hosted, open-source chat UI for talking to LLMs from OpenAI and Anthropic. It runs entirely in your browser as a static site â€” your API keys and conversations never leave your device.

It's designed for developers and power users who want a clean, fast chat interface without handing their data to a third party.

## Key Features

- **Multi-provider, multi-model** â€” Switch between GPT-4o, GPT-3.5, o1, Claude Sonnet 4, Claude Opus 4.5, and more from a single interface
- **Streaming responses** â€” Real-time token-by-token output as the model generates
- **Multiple conversations** â€” Create, rename, delete, and switch between chats with full context history
- **Markdown + syntax highlighting** â€” Rendered messages with code blocks, tables, lists, and links
- **System prompts** â€” Per-conversation custom instructions
- **Export** â€” Download any conversation as JSON or Markdown
- **Dark / Light theme** â€” Follows system preference or manual toggle
- **Fully responsive** â€” Desktop, tablet, and phone with touch-optimized UI, safe area support for notched devices, and mobile bottom-sheet modals
- **First-time user guide** â€” Built-in walkthrough for getting API keys from each provider
- **Optional API proxy** â€” Included Cloudflare Worker proxy for CORS-free requests and keeping keys off the browser network tab
- **Privacy controls** â€” Choose between session storage (cleared on tab close) or local storage for API keys

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Static Frontend (React + Vite) â”‚  â† Deployed to Cloudflare Pages / Vercel / Netlify
â”‚  Runs entirely in the browser   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Optional       â”‚
       â”‚  CF Worker Proxyâ”‚  â† Relays requests, never stores keys
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  LLM Provider   â”‚
       â”‚  (OpenAI /      â”‚
       â”‚   Anthropic)    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Without the proxy, the browser calls providers directly. Either way, nothing is stored server-side.

## Tech Stack

| Layer | Technology |
|---|---|
| Framework | **React 18** with **TypeScript** |
| Build | **Vite 5** |
| Styling | **Tailwind CSS 3** |
| State | **Zustand** |
| Markdown | **react-markdown** + remark-gfm + rehype-highlight |
| Syntax highlighting | **highlight.js** |
| API proxy | **Cloudflare Workers** |
| Hosting | **Cloudflare Pages** (or any static host) |

## Privacy & Security

- API keys are stored in your browser only â€” `sessionStorage` (default, cleared on tab close) or `localStorage` (persists)
- All calls go directly to the LLM provider, or through your own proxy â€” never through any third-party server
- Zero telemetry, zero analytics, zero cookies
- The proxy Worker forwards your key in a header and discards it immediately â€” nothing is logged or persisted
- Conversations are stored in `localStorage` and never leave the browser

## License

MIT
